{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cf19ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eee2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1) # conv5와 fc1 사이에 view 들어간다.\n",
    "        self.fc1 = nn.Linear(in_features=256 * 5 * 5, out_features=4096) # fc layer 6 * 6 -> 5 * 5\n",
    "        self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096, out_features=4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # 4차원을 1차원으로 펼쳐주는 층 (역할) -> flatten\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "    \n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca6c0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          34,944\n",
      "            Conv2d-2          [-1, 256, 26, 26]         614,656\n",
      "            Conv2d-3          [-1, 384, 12, 12]         885,120\n",
      "            Conv2d-4          [-1, 384, 12, 12]       1,327,488\n",
      "            Conv2d-5          [-1, 256, 12, 12]         884,992\n",
      "            Linear-6                 [-1, 4096]      26,218,496\n",
      "            Linear-7                 [-1, 4096]      16,781,312\n",
      "            Linear-8                    [-1, 4]          16,388\n",
      "================================================================\n",
      "Total params: 46,763,396\n",
      "Trainable params: 46,763,396\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 4.64\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 183.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94aa3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdongju_coredottoday\u001b[0m (\u001b[33mcoredottoday-dongju\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7acc8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagefloder 생성\n",
    "train_imgfolder = ImageFolder(root='data/train',\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Resize(224),\n",
    "                          transforms.RandomHorizontalFlip(p=0.8),\n",
    "                          transforms.GaussianBlur(kernel_size=(19, 19), sigma=(1.0, 2.0)),\n",
    "                          transforms.RandomRotation(degrees=(-30, 30), interpolation=transforms.InterpolationMode.BILINEAR, fill=0),\n",
    "                          transforms.CenterCrop(224)\n",
    "                      ]))\n",
    "\n",
    "\n",
    "validation_imgfolder = ImageFolder(root='data/validation',\n",
    "                          transform=transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Resize(224),\n",
    "                          transforms.CenterCrop(224)\n",
    "                      ]))\n",
    "\n",
    "\n",
    "test_imgfolder = ImageFolder(root='data/test',\n",
    "                      transform=transforms.Compose([\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Resize(224),\n",
    "                          transforms.CenterCrop(224)\n",
    "                      ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209ca9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data_loader\n",
    "train_data_loader = DataLoader(dataset=train_imgfolder, \n",
    "                         batch_size=16, \n",
    "                         num_workers=0,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True\n",
    "                        )\n",
    "\n",
    "valid_data_loader = DataLoader(dataset=validation_imgfolder, \n",
    "                         batch_size=16, \n",
    "                         num_workers=0\n",
    "                        )\n",
    "\n",
    "test_data_loader = DataLoader(dataset=test_imgfolder, \n",
    "                         batch_size=1, \n",
    "                         num_workers=0\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15cfee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e8f1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "model.apply(normal_init)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.0001)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d8e3dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/corenas/dongju/pbl/wandb/run-20231125_085235-8vrm0t7r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coredottoday-dongju/pbl/runs/8vrm0t7r' target=\"_blank\">elated-aardvark-3</a></strong> to <a href='https://wandb.ai/coredottoday-dongju/pbl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coredottoday-dongju/pbl' target=\"_blank\">https://wandb.ai/coredottoday-dongju/pbl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coredottoday-dongju/pbl/runs/8vrm0t7r' target=\"_blank\">https://wandb.ai/coredottoday-dongju/pbl/runs/8vrm0t7r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"pbl\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"eprchs\": num_epochs\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3c53790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datanum = len(train_data_loader)*batch_size\n",
    "valid_datanum = len(valid_data_loader)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a445f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Epoch [1/100] Loss: 1.3291 Accuracy: 0.3764\n",
      "Epoch [1/100] val_Loss: 1.3976 val_Accuracy: 0.2500\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [2/100] Loss: 1.1188 Accuracy: 0.4741\n",
      "Epoch [2/100] val_Loss: 1.0274 val_Accuracy: 0.5625\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [3/100] Loss: 0.7855 Accuracy: 0.7069\n",
      "Epoch [3/100] val_Loss: 0.7418 val_Accuracy: 0.7188\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [4/100] Loss: 0.6989 Accuracy: 0.7486\n",
      "Epoch [4/100] val_Loss: 0.6743 val_Accuracy: 0.7500\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [5/100] Loss: 0.6113 Accuracy: 0.7730\n",
      "Epoch [5/100] val_Loss: 0.6837 val_Accuracy: 0.7344\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [6/100] Loss: 0.5592 Accuracy: 0.7953\n",
      "Epoch [6/100] val_Loss: 1.1164 val_Accuracy: 0.7188\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [7/100] Loss: 0.5555 Accuracy: 0.8017\n",
      "Epoch [7/100] val_Loss: 0.7114 val_Accuracy: 0.6875\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [8/100] Loss: 0.4727 Accuracy: 0.8276\n",
      "Epoch [8/100] val_Loss: 0.8224 val_Accuracy: 0.7031\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [9/100] Loss: 0.4326 Accuracy: 0.8499\n",
      "Epoch [9/100] val_Loss: 0.8596 val_Accuracy: 0.7188\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [10/100] Loss: 0.4143 Accuracy: 0.8534\n",
      "Epoch [10/100] val_Loss: 0.7742 val_Accuracy: 0.7188\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [11/100] Loss: 0.3683 Accuracy: 0.8685\n",
      "Epoch [11/100] val_Loss: 0.3931 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [12/100] Loss: 0.3588 Accuracy: 0.8807\n",
      "Epoch [12/100] val_Loss: 0.4493 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [13/100] Loss: 0.3412 Accuracy: 0.8793\n",
      "Epoch [13/100] val_Loss: 0.6528 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [14/100] Loss: 0.3348 Accuracy: 0.8822\n",
      "Epoch [14/100] val_Loss: 0.6067 val_Accuracy: 0.7500\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [15/100] Loss: 0.2958 Accuracy: 0.8930\n",
      "Epoch [15/100] val_Loss: 0.5678 val_Accuracy: 0.7812\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [16/100] Loss: 0.2784 Accuracy: 0.9009\n",
      "Epoch [16/100] val_Loss: 0.4001 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [17/100] Loss: 0.3211 Accuracy: 0.8937\n",
      "Epoch [17/100] val_Loss: 0.3506 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [18/100] Loss: 0.2716 Accuracy: 0.9045\n",
      "Epoch [18/100] val_Loss: 0.5117 val_Accuracy: 0.7812\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [19/100] Loss: 0.2459 Accuracy: 0.9080\n",
      "Epoch [19/100] val_Loss: 0.4983 val_Accuracy: 0.7969\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [20/100] Loss: 0.2712 Accuracy: 0.9001\n",
      "Epoch [20/100] val_Loss: 0.2094 val_Accuracy: 0.9531\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [21/100] Loss: 0.2781 Accuracy: 0.9016\n",
      "Epoch [21/100] val_Loss: 0.3534 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [22/100] Loss: 0.2356 Accuracy: 0.9145\n",
      "Epoch [22/100] val_Loss: 0.3708 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [23/100] Loss: 0.2472 Accuracy: 0.9217\n",
      "Epoch [23/100] val_Loss: 0.4576 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [24/100] Loss: 0.1758 Accuracy: 0.9375\n",
      "Epoch [24/100] val_Loss: 0.4436 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [25/100] Loss: 0.1937 Accuracy: 0.9310\n",
      "Epoch [25/100] val_Loss: 0.5003 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [26/100] Loss: 0.2482 Accuracy: 0.9145\n",
      "Epoch [26/100] val_Loss: 0.4396 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [27/100] Loss: 0.1837 Accuracy: 0.9375\n",
      "Epoch [27/100] val_Loss: 0.4787 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [28/100] Loss: 0.1349 Accuracy: 0.9533\n",
      "Epoch [28/100] val_Loss: 0.2646 val_Accuracy: 0.9219\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [29/100] Loss: 0.1727 Accuracy: 0.9476\n",
      "Epoch [29/100] val_Loss: 0.4486 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [30/100] Loss: 0.1529 Accuracy: 0.9476\n",
      "Epoch [30/100] val_Loss: 0.5424 val_Accuracy: 0.7969\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [31/100] Loss: 0.1401 Accuracy: 0.9511\n",
      "Epoch [31/100] val_Loss: 0.3660 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [32/100] Loss: 0.1209 Accuracy: 0.9612\n",
      "Epoch [32/100] val_Loss: 0.3092 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [33/100] Loss: 0.1360 Accuracy: 0.9576\n",
      "Epoch [33/100] val_Loss: 0.5006 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [34/100] Loss: 0.1370 Accuracy: 0.9497\n",
      "Epoch [34/100] val_Loss: 0.2965 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [35/100] Loss: 0.1545 Accuracy: 0.9432\n",
      "Epoch [35/100] val_Loss: 0.7059 val_Accuracy: 0.7812\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [36/100] Loss: 0.1196 Accuracy: 0.9619\n",
      "Epoch [36/100] val_Loss: 0.4646 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [37/100] Loss: 0.1294 Accuracy: 0.9569\n",
      "Epoch [37/100] val_Loss: 0.4629 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [38/100] Loss: 0.1396 Accuracy: 0.9447\n",
      "Epoch [38/100] val_Loss: 0.3953 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [39/100] Loss: 0.0886 Accuracy: 0.9677\n",
      "Epoch [39/100] val_Loss: 0.5637 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [40/100] Loss: 0.0999 Accuracy: 0.9634\n",
      "Epoch [40/100] val_Loss: 0.4811 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [41/100] Loss: 0.1207 Accuracy: 0.9547\n",
      "Epoch [41/100] val_Loss: 0.3982 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [42/100] Loss: 0.0933 Accuracy: 0.9713\n",
      "Epoch [42/100] val_Loss: 0.4846 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [43/100] Loss: 0.0781 Accuracy: 0.9713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] val_Loss: 0.4712 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [44/100] Loss: 0.0709 Accuracy: 0.9763\n",
      "Epoch [44/100] val_Loss: 0.5328 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [45/100] Loss: 0.0949 Accuracy: 0.9684\n",
      "Epoch [45/100] val_Loss: 0.4274 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [46/100] Loss: 0.0886 Accuracy: 0.9713\n",
      "Epoch [46/100] val_Loss: 0.4563 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [47/100] Loss: 0.0768 Accuracy: 0.9749\n",
      "Epoch [47/100] val_Loss: 0.5086 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [48/100] Loss: 0.0778 Accuracy: 0.9763\n",
      "Epoch [48/100] val_Loss: 0.7122 val_Accuracy: 0.7656\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [49/100] Loss: 0.0754 Accuracy: 0.9705\n",
      "Epoch [49/100] val_Loss: 0.4349 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [50/100] Loss: 0.0742 Accuracy: 0.9727\n",
      "Epoch [50/100] val_Loss: 0.3995 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [51/100] Loss: 0.0901 Accuracy: 0.9698\n",
      "Epoch [51/100] val_Loss: 0.4430 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [52/100] Loss: 0.0797 Accuracy: 0.9727\n",
      "Epoch [52/100] val_Loss: 0.5670 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [53/100] Loss: 0.0590 Accuracy: 0.9784\n",
      "Epoch [53/100] val_Loss: 0.3120 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [54/100] Loss: 0.0477 Accuracy: 0.9820\n",
      "Epoch [54/100] val_Loss: 0.4921 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [55/100] Loss: 0.0777 Accuracy: 0.9734\n",
      "Epoch [55/100] val_Loss: 0.3175 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [56/100] Loss: 0.0414 Accuracy: 0.9885\n",
      "Epoch [56/100] val_Loss: 0.4092 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [57/100] Loss: 0.0520 Accuracy: 0.9849\n",
      "Epoch [57/100] val_Loss: 0.7710 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [58/100] Loss: 0.0391 Accuracy: 0.9892\n",
      "Epoch [58/100] val_Loss: 0.3152 val_Accuracy: 0.9531\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [59/100] Loss: 0.0254 Accuracy: 0.9914\n",
      "Epoch [59/100] val_Loss: 0.5977 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "Epoch [62/100] val_Loss: 0.3513 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [63/100] Loss: 0.0816 Accuracy: 0.9720\n",
      "Epoch [63/100] val_Loss: 0.6403 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [64/100] Loss: 0.0729 Accuracy: 0.9756\n",
      "Epoch [64/100] val_Loss: 0.4946 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [65/100] Loss: 0.0397 Accuracy: 0.9864\n",
      "Epoch [65/100] val_Loss: 0.4804 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [66/100] Loss: 0.0650 Accuracy: 0.9799\n",
      "Epoch [66/100] val_Loss: 0.4055 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [67/100] Loss: 0.0379 Accuracy: 0.9878\n",
      "Epoch [67/100] val_Loss: 0.6273 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [68/100] Loss: 0.0225 Accuracy: 0.9921\n",
      "Epoch [68/100] val_Loss: 0.5803 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [69/100] Loss: 0.0259 Accuracy: 0.9914\n",
      "Epoch [69/100] val_Loss: 0.7385 val_Accuracy: 0.7969\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [70/100] Loss: 0.0238 Accuracy: 0.9935\n",
      "Epoch [70/100] val_Loss: 0.6266 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [71/100] Loss: 0.0613 Accuracy: 0.9820\n",
      "Epoch [71/100] val_Loss: 0.5558 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [72/100] Loss: 0.0305 Accuracy: 0.9878\n",
      "Epoch [72/100] val_Loss: 0.3632 val_Accuracy: 0.9219\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [73/100] Loss: 0.0335 Accuracy: 0.9907\n",
      "Epoch [73/100] val_Loss: 0.5518 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [74/100] Loss: 0.0290 Accuracy: 0.9871\n",
      "Epoch [74/100] val_Loss: 0.4013 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [75/100] Loss: 0.0532 Accuracy: 0.9835\n",
      "Epoch [75/100] val_Loss: 0.4379 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [76/100] Loss: 0.0821 Accuracy: 0.9763\n",
      "Epoch [76/100] val_Loss: 0.4767 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [77/100] Loss: 0.0363 Accuracy: 0.9856\n",
      "Epoch [77/100] val_Loss: 0.6130 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [78/100] Loss: 0.0428 Accuracy: 0.9856\n",
      "Epoch [78/100] val_Loss: 0.4188 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [79/100] Loss: 0.0315 Accuracy: 0.9928\n",
      "Epoch [79/100] val_Loss: 0.5306 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [80/100] Loss: 0.0225 Accuracy: 0.9921\n",
      "Epoch [80/100] val_Loss: 0.4928 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [81/100] Loss: 0.0412 Accuracy: 0.9856\n",
      "Epoch [81/100] val_Loss: 0.9206 val_Accuracy: 0.7812\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [82/100] Loss: 0.0593 Accuracy: 0.9792\n",
      "Epoch [82/100] val_Loss: 0.3887 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [83/100] Loss: 0.0308 Accuracy: 0.9864\n",
      "Epoch [83/100] val_Loss: 0.3777 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [84/100] Loss: 0.0317 Accuracy: 0.9892\n",
      "Epoch [84/100] val_Loss: 0.7521 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [85/100] Loss: 0.0192 Accuracy: 0.9950\n",
      "Epoch [85/100] val_Loss: 0.5085 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [86/100] Loss: 0.0377 Accuracy: 0.9856\n",
      "Epoch [86/100] val_Loss: 0.9605 val_Accuracy: 0.8125\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [87/100] Loss: 0.0722 Accuracy: 0.9792\n",
      "Epoch [87/100] val_Loss: 0.4435 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [88/100] Loss: 0.0515 Accuracy: 0.9799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100] val_Loss: 0.3558 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [89/100] Loss: 0.0546 Accuracy: 0.9792\n",
      "Epoch [89/100] val_Loss: 0.4733 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [90/100] Loss: 0.0345 Accuracy: 0.9864\n",
      "Epoch [90/100] val_Loss: 0.4101 val_Accuracy: 0.8906\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [91/100] Loss: 0.0205 Accuracy: 0.9914\n",
      "Epoch [91/100] val_Loss: 0.5733 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [92/100] Loss: 0.0290 Accuracy: 0.9892\n",
      "Epoch [92/100] val_Loss: 0.9904 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [93/100] Loss: 0.0316 Accuracy: 0.9878\n",
      "Epoch [93/100] val_Loss: 0.5527 val_Accuracy: 0.8750\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [94/100] Loss: 0.0205 Accuracy: 0.9935\n",
      "Epoch [94/100] val_Loss: 0.5711 val_Accuracy: 0.8281\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [95/100] Loss: 0.0439 Accuracy: 0.9878\n",
      "Epoch [95/100] val_Loss: 0.3980 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [96/100] Loss: 0.0216 Accuracy: 0.9943\n",
      "Epoch [96/100] val_Loss: 0.4449 val_Accuracy: 0.8594\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [97/100] Loss: 0.0367 Accuracy: 0.9849\n",
      "Epoch [97/100] val_Loss: 0.4622 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [98/100] Loss: 0.0143 Accuracy: 0.9935\n",
      "Epoch [98/100] val_Loss: 0.4404 val_Accuracy: 0.9062\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [99/100] Loss: 0.0462 Accuracy: 0.9871\n",
      "Epoch [99/100] val_Loss: 0.4057 val_Accuracy: 0.9375\n",
      "-----------------next-----------------\n",
      "--------------------------------------------------------\n",
      "Epoch [100/100] Loss: 0.0159 Accuracy: 0.9957\n",
      "Epoch [100/100] val_Loss: 0.5332 val_Accuracy: 0.8438\n",
      "-----------------next-----------------\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for train_x, train_y in train_data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x.cuda())\n",
    "        \n",
    "        loss = criterion(output.cpu(), train_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "        correct += (train_y == predicted.cpu()).sum()\n",
    "\n",
    "    print(f'--------------------------------------------------------')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss_sum/len(train_data_loader):.4f} Accuracy: {correct / train_datanum:.4f}')\n",
    "    train_loss = loss_sum/len(train_data_loader)\n",
    "    train_acc = correct / train_datanum\n",
    "\n",
    "    val_loss_sum = 0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for valid_x, valid_y in valid_data_loader:\n",
    "            valid_x = valid_x.to('cuda')\n",
    "\n",
    "            val_output = model(valid_x)\n",
    "            val_loss = criterion(val_output.cpu(), valid_y)\n",
    "            val_loss_sum += val_loss.item()\n",
    "            \n",
    "            val_predicted = torch.max(val_output, 1)[1]\n",
    "            val_correct += (valid_y == val_predicted.cpu()).sum()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] val_Loss: {val_loss_sum/len(valid_data_loader):.4f} val_Accuracy: {val_correct / valid_datanum:.4f}')\n",
    "\n",
    "    validation_loss = val_loss_sum/len(valid_data_loader)\n",
    "    validation_acc = val_correct / valid_datanum\n",
    "    \n",
    "    \n",
    "    wandb.log({\"train_acc\":train_acc,\"train_loss\":train_loss,\"validation_acc\":validation_acc,\"validation_loss\":validation_loss})\n",
    "        \n",
    "    print('-----------------next-----------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
